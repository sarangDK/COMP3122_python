{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXQSrVGLbfCq"
   },
   "source": [
    "# Lab 4: Basic regression - Predict fuel efficiency\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9HUhbCGbfCr"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # we use this library to load the dataset\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ceGRpBIbfCs"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "# Load the 'mpg' dataset using seaborn library into a Pandas DataFrame\n",
    "df = sns.load_dataset('mpg') # mpg -> miles per galion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfxdDYPNbfCs"
   },
   "source": [
    "MPG dataset can be viewed online at  \n",
    "https://github.com/mwaskom/seaborn-data/blob/master/mpg.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzRgjAwp9hYw"
   },
   "source": [
    "## Data Exploration - Pandas Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ESV9y917bfCt"
   },
   "source": [
    "### Show the first 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "0  18.0          8         307.0       130.0    3504          12.0   \n",
       "1  15.0          8         350.0       165.0    3693          11.5   \n",
       "2  18.0          8         318.0       150.0    3436          11.0   \n",
       "3  16.0          8         304.0       150.0    3433          12.0   \n",
       "4  17.0          8         302.0       140.0    3449          10.5   \n",
       "\n",
       "   model_year origin                       name  \n",
       "0          70    usa  chevrolet chevelle malibu  \n",
       "1          70    usa          buick skylark 320  \n",
       "2          70    usa         plymouth satellite  \n",
       "3          70    usa              amc rebel sst  \n",
       "4          70    usa                ford torino  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5UukwBAdgXb"
   },
   "source": [
    "### Show the size of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3582"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code here\n",
    "df.size # Notic that from 398 rows x 9 columns = 3582\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4UwwzRrd9WY"
   },
   "source": [
    "### Find the columns name and their types (numerical or categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['mpg', 'cylinders', 'displacement', 'horsepower', 'weight',\n",
      "       'acceleration', 'model_year', 'origin', 'name'],\n",
      "      dtype='object')\n",
      "mpg\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Series name: mpg\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "398 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 3.2 KB\n",
      "None\n",
      "cylinders\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Series name: cylinders\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "398 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 3.2 KB\n",
      "None\n",
      "displacement\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Series name: displacement\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "398 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 3.2 KB\n",
      "None\n",
      "horsepower\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Series name: horsepower\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "392 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 3.2 KB\n",
      "None\n",
      "weight\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Series name: weight\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "398 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 3.2 KB\n",
      "None\n",
      "acceleration\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Series name: acceleration\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "398 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 3.2 KB\n",
      "None\n",
      "model_year\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Series name: model_year\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "398 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 3.2 KB\n",
      "None\n",
      "origin\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Series name: origin\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "398 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.2+ KB\n",
      "None\n",
      "name\n",
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Series name: name\n",
      "Non-Null Count  Dtype \n",
      "--------------  ----- \n",
      "398 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.2+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 398 entries, 0 to 397\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   mpg           398 non-null    float64\n",
      " 1   cylinders     398 non-null    int64  \n",
      " 2   displacement  398 non-null    float64\n",
      " 3   horsepower    392 non-null    float64\n",
      " 4   weight        398 non-null    int64  \n",
      " 5   acceleration  398 non-null    float64\n",
      " 6   model_year    398 non-null    int64  \n",
      " 7   origin        398 non-null    object \n",
      " 8   name          398 non-null    object \n",
      "dtypes: float64(4), int64(3), object(2)\n",
      "memory usage: 28.1+ KB\n",
      "None\n",
      "              mpg   cylinders  displacement  horsepower       weight  \\\n",
      "count  398.000000  398.000000    398.000000  392.000000   398.000000   \n",
      "mean    23.514573    5.454774    193.425879  104.469388  2970.424623   \n",
      "std      7.815984    1.701004    104.269838   38.491160   846.841774   \n",
      "min      9.000000    3.000000     68.000000   46.000000  1613.000000   \n",
      "25%     17.500000    4.000000    104.250000   75.000000  2223.750000   \n",
      "50%     23.000000    4.000000    148.500000   93.500000  2803.500000   \n",
      "75%     29.000000    8.000000    262.000000  126.000000  3608.000000   \n",
      "max     46.600000    8.000000    455.000000  230.000000  5140.000000   \n",
      "\n",
      "       acceleration  model_year  \n",
      "count    398.000000  398.000000  \n",
      "mean      15.568090   76.010050  \n",
      "std        2.757689    3.697627  \n",
      "min        8.000000   70.000000  \n",
      "25%       13.825000   73.000000  \n",
      "50%       15.500000   76.000000  \n",
      "75%       17.175000   79.000000  \n",
      "max       24.800000   82.000000  \n",
      "mpg             float64\n",
      "cylinders         int64\n",
      "displacement    float64\n",
      "horsepower      float64\n",
      "weight            int64\n",
      "acceleration    float64\n",
      "model_year        int64\n",
      "origin           object\n",
      "name             object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#your code here\n",
    "# print the columns name\n",
    "print(df.columns)\n",
    "\n",
    "for singleColumn in df.columns:\n",
    "  print(singleColumn)\n",
    "  print(df[singleColumn].info())\n",
    "\n",
    "print(df.info()) # gers datatypes and the null/not null counts\n",
    "print(df.describe())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heVHvJgZhc53"
   },
   "source": [
    "### Find the number of missing values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "# horsepower 392 non-null float64\n",
    "\n",
    "print(df.isna().sum())  # count all of the NA values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJyFFJi_j186"
   },
   "source": [
    "### Handle the missing values in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "695skg69ikSP"
   },
   "source": [
    "Since the number of missing values is low, we can simply drop the rows containing them. However, as a practice and review, let's substitute the missing values in the numerical columns (if any) with the mean of the respective column and the missing values in the categorical columns (if any) with the median of the respective column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#your solution here\n",
    "\n",
    "#df.select_dtypes(include = np.number) => filters the dataframe to include only columns with numerical data types\n",
    "\n",
    "# .columns => extract the names of these selected columns\n",
    "numberOnlyColumns = df.select_dtypes(include=np.number).columns # only numerical values column\n",
    "\n",
    "df[numberOnlyColumns] = df[numberOnlyColumns].fillna(df[numberOnlyColumns].mean())\n",
    "# fillna -> is a pandas method used to fill missing values(NaN) in a Dataframe or series\n",
    "# filling with (df[numberOnlyColumns].mean()) -> calculates the mean of each numerical column, ignoring missing values\n",
    "\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXeUz8BArqXK"
   },
   "source": [
    "### Compute the average and the median weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "print(df.weight.mean())\n",
    "print(df.weight.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eb5hLSIYsZE1"
   },
   "source": [
    "### Find the number of cars that weight more than 2000 kgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "df[df.weight > 2000 * 2.2].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3nE8VBksl20"
   },
   "source": [
    "### Find how many cars there are for each number of cylinders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "df.cylinders.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4ofBIrVtQRS"
   },
   "source": [
    "### Find what are the car models with number of cylinders (3 or 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "# 그룹화 (Groupby)\n",
    "print(df.name.groupby(df.cylinders).get_group(3)) # cylinders 컬럼을 기준으로 name 컬럼을 그룹화 / .get_group(3) -> cylinders == 3 인 데이터 출력\n",
    "print(df.name.groupby(df.cylinders).get_group(5))\n",
    "# print(df.groupby(\"cylinders\").count().name[0:3:2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35WxtvxtU-X_"
   },
   "source": [
    "### Show the `value_counts()` of `origin` column or show the unique values of this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "print(df.origin.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QGRxYTsrXLJf"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FzIQgkXiVYBX"
   },
   "source": [
    "### Use one hot encoding to change the categorical values of `origin` column to numerical values.\n",
    "\n",
    "(One - Hot - Encoding) 은 범주형 데이터 (Categorical Data) 를 머신러닝 모델이 이해 할수있도록 숫자로 변환하는 기법\n",
    "\n",
    "why ?\n",
    "-> 범주형 데이터 (카테고리 데이터)를 직접 숫자로 변환하면 문제발생\n",
    "-> 숫자의 크기 차이가 의미를 갖지 않도록 변환해야 함\n",
    "\n",
    "- use `pd.get_dummies()` method to do the encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "df = pd.get_dummies(df, columns=['origin'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AtLp74JWXPp6"
   },
   "source": [
    "### Remove the name column form the dataframe to have all numerical dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "df_preprocessed = df.drop('name', axis=1) # axis=1 specifies column removal\n",
    "df_preprocessed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VuJ1dAYdY8JM"
   },
   "source": [
    "### Does the input needs reshaping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "print(df_preprocessed.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDwS5PqJaqb7"
   },
   "source": [
    "### Split the data into training and test sets and form `train_features`, `train_labels`, `test_features`, `test_labels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#your code here\n",
    "train_X, train_y, test_X, test_y = train_test_split(df_preprocessed, test_size=0.2, random_state=66)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "\n",
    "train_labels = train_df.iloc[:, 0] # This column is the mpg column which we have chosen as the label/target/answer\n",
    "train_features = train_df.iloc[:, 1:] # This column is the mpg column which we have chosen as the label/target/answer\n",
    "\n",
    "test_labels = test_df.iloc[:, 0] # This column is the mpg column which we have chosen as the label/target/answer\n",
    "test_features = test_df.iloc[:, 1:] # This column is the mpg column which we have chosen as the label\n",
    "\n",
    "\n",
    "print(train_features.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_features.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePcXIunjxLGW"
   },
   "source": [
    "### For simplicity in the following steps, convert the dataset from a pandas DataFrame to a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "train_features = np.array(train_features)\n",
    "train_labels = np.array(train_labels)\n",
    "test_features = np.array(test_features)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCfztMDkyeLX"
   },
   "source": [
    "## Normalization layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWPepaJ20buG"
   },
   "source": [
    "To ensure stable training of neural networks, we typically normalize the data. This process also enhances the convergence of the gradient descent algorithm.\n",
    "\n",
    "There is not single way to normalize the data. You can also use `scikit-learn `or `pandas` to do it. However, in this lab, we will use the normalization layer provided by tensorflow which matches the other parts of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfuJRF3syqJL"
   },
   "source": [
    "The `tf.keras.layers.Normalization` is a clean and simple way to add feature normalization into your model.\n",
    "\n",
    "The first step is to create the layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "# axis= -1 -> 마지막 차원(각 특성별, feature-wise) 기준으로 정규화\n",
    "# 즉 , 각 열(특성)에 대해 평균을 0, 분산을 1로 조정\n",
    "\n",
    "# Normalization 레이어란 ?\n",
    "# -> tf.keras.layers.normalization 은 입력 데이터를 정규화 하는 keras 레이어\n",
    "# 데이터를 평균 0, 분산1이 되도록 변환해서 학습을 더 빠르고 안정적으로 진행할수있도록 도움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsvUWg8dy8TA"
   },
   "source": [
    "Then, fit the state of the preprocessing layer to the data by calling `Normalization.adapt`.\n",
    "\n",
    "It calculates the mean and variance of each feature, and store them in the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "normalizer.adapt(train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQqwlS4HzXeM"
   },
   "source": [
    "When the layer is called, it returns the input data, with each feature independently normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "first = train_features[0]\n",
    "print('First example:', first)\n",
    "print()\n",
    "print('Normalized:', normalizer(first).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8u33n29vmFJ"
   },
   "source": [
    "## **Approach #1:** Regression using `Linear Regression`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6anRxth1MXq"
   },
   "source": [
    "**You are welcome to use scikit-learn to perform linear regression on this dataset.**\n",
    "\n",
    "However, here we aim to implement it using TensorFlow.\n",
    "\n",
    "- As we saw in Lab Week 2, `logistic regression` is essentially a single neuron with a `sigmoid` activation function.\n",
    "\n",
    "- Similarly, `linear regression` can be viewed as a single neuron with a `linear` activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZbWqUxQa2jjY"
   },
   "source": [
    "### **Step 1:** Linear regression model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "linear_model = tf.keras.Sequential([\n",
    "    normalizer,\n",
    "    layers.Dense(1, activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQFUB3OEuprH"
   },
   "source": [
    "**Note:** You can define your model all at once like the cell above or you can buid the model incrementaly  (suitable for your assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "# Defining the model incrementaly (suitable for your assignment)\n",
    "linear_model = tf.keras.Sequential()\n",
    "linear_model.add(normalizer)\n",
    "linear_model.add(layers.Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CpCRMAeW2o0-"
   },
   "source": [
    "### **Step 2:** Configure the model with Keras `Model.compile()`\n",
    "\n",
    "The most important arguments to compile are the `loss` and the `optimizer`, since these define what will be optimized (`\"mean_absolute_error\"`) and how (using the `tf.keras.optimizers.Adam(learning_rate=0.1)`).\n",
    "\n",
    "**arguments:**\n",
    "- optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "- loss='mean_absolute_error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#your code here\n",
    "linear_model.compile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yAwyyRjF4cfv"
   },
   "source": [
    "### **Step 3:** Train the model using the `Model.fit()` for `100` epochs, and store the output in a variable named history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "history = linear_model.fit(train_features, train_labels, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "  plt.plot(history.history['loss'], label='loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Error [MPG]')\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "\n",
    "plot_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwfYnu3cuprI"
   },
   "source": [
    "### Get the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "linear_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASE-T2jk6cAN"
   },
   "source": [
    "### **Step 4:** Evaluate the linear model on the test set using Keras `Model.evaluate()` and see the `mean_absolute_error` and save the result for future comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWfd69aOXkQD"
   },
   "source": [
    "## **Approach #2:** Regression using a `Deep Neural Network (DNN)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1P1NT4XmYgxv"
   },
   "source": [
    "### Solve the same problem and using deep neural network with the sample architecture;\n",
    "- 1st hidden layer no. of units =  64\n",
    "- 2nd hidden layer no. of units = 64\n",
    "- Choose appropriate `activation` functions for hidden and output layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hbrx1g4PuprJ"
   },
   "source": [
    "### Print the model summary (after training). How many parameters are there in the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1epkt7v3uprJ"
   },
   "source": [
    "### You can see even this small model has more than 4000 trainable parameters. The more the number of parameters, the longer the training time and cost. Search the net and see how many trainable parameters does the `ChatGPT` model have? What about `DeepSeek` model? (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oX-BabwxGI6B"
   },
   "source": [
    "## Compare the evaluation result of the two approaches, i.e., linear regression and deep neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnvzqXkXuprJ"
   },
   "source": [
    "## Use the following large model and evaluate it on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "model_dnn_large = tf.keras.Sequential([\n",
    "    normalizer,\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='linear')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hr6sAuLMuprK"
   },
   "source": [
    "### Explain your observation. Why do you think the large model is not performing well?\n",
    "\n",
    "- hint: when the number of trainable parameters is very large (even larger than the number of data points), the model may overfit the training data.One way to solve this problem is to use more data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4l0dWGn2uprK"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "https://github.com/PyDataGBC/PyML2025/blob/main/LabWeek4/LabWeek4.ipynb",
     "timestamp": 1738256615232
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
